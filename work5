import requests
import json
import pandas as pd
%matplotlib inline
from bs4 import BeautifulSoup
import numpy as no
import matplotlib.pyplot as plt

LP_destinations = pd.read_csv('destinations_LP_crawler_Ex5.csv')

def find_country(city):
    try:
        key = "AIzaSyA1p2cr7liy7p6AQTfZmT5jqq-x9mx6dKA"
        url = 'https://maps.googleapis.com/maps/api/geocode/json?address=%s&key=%s' % (city,key)
        data = requests.get(url)
        if data.status_code == 200:
            try:
                data = data.json()
                return data['results'][0]['address_components'][2]['long_name']
            except:
                return ''
        else:
            return ''
    except:
        return''
        
        
def find_description(country, city):
    try:
        url = 'https://www.lonelyplanet.com/' + country + '/' + city
        html = requests.get(url)
        soup = BeautifulSoup(html.content, 'html.parser')
        a = soup.find_all('section', class_ = 'text-black-400')
        
        descrip = ''
        for p in a[0].findAll('p'):
            descrip = descrip + str(p.get_text()) + "\n"
        return descrip
    except:
        return''
        
        
countrys = list()
description = list()
i = 0
coun = ''
des = ''
city_LP = ''

for city in LP_destinations['city']:
    city_LP = LP_destinations.loc[i,'city_LP']
    coun = find_country(city)
    if coun != '':
        des = find_description(coun, city_LP)   
        countrys.append(coun)
        description.append(des)
    else:
        countrys.append('')
        description.append('')
        
    i = i + 1
LP_destinations['countrys'] = countrys
LP_destinations["description"] = description

LP_destinations.to_csv(r'C:\Users\itays\Desktop\LP_destinations.csv')

    
    
    
